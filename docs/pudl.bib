@techreport{EISecLeg2019,
  author      = {Mike O'Boyle and Ron Lehr},
  annote      = {This issue brief compares new securitization legislation in Colorado, Montana, and New Mexico to refinance utility investments in early-retired electric generation plants. As similar legislation is considered in other states, these comparisons can support legislators deciding how much protection to offer consumers and how to evaluate public interest values and utility interests.},
  title       = {Comparing 2019 Securitization Legislation In Colorado, Montana, and New Mexico},
  institution = {Energy Innovation},
  year        = {2020},
  url         = {https://energyinnovation.org/publication/comparing-2019-securitization-legislation-in-colorado-montana-and-new-mexico/},
  urldate     = {2021-10-12},
  type        = {Report},
}

@misc{pudl,
  author    = {Selvans, Zane and
               Gosnell, Christina and
               Sharpe, Austen and
               Winter, Steven and
               Bush, Trenton and
               Rousik, Jan and
               Welty, Ethan},
  title     = {The {P}ublic {U}tility {D}ata {L}iberation ({PUDL}) {P}roject},
  month     = aug,
  year      = 2021,
  howpublished = {Git{H}ub repository archived on {Z}enodo},
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.3404014},
  url       = {https://doi.org/10.5281/zenodo.3404014},
}

@article{AbernathayARCO
  author={Abernathey, Ryan P. and
          Augspurger, Tom and
          Banihirwe, Anderson and
          Blackmon-Luca, Charles C. and
          Crone, Timothy J. and
          Gentemann, Chelle L. and
          Hamman, Joseph J. and
          Henderson, Naomi and
          Lepore, Chiara and
          McCaie, Theo A. and
          Robinson, Niall H. and
          Signell, Richard P.},
  journal={Computing in Science & Engineering},
  title={Cloud-Native Repositories for Big Scientific Data},
  year={2021},
  volume={23},
  number={2},
  pages={26-35},
  abstract={
     Scientific data have traditionally been distributed via downloads from data server
     to local computer. This way of working suffers from limitations as scientific
     datasets grow toward the petabyte scale. A “cloud-native data repository,” as
     defined in this article, offers several advantages over traditional data
     repositories-performance, reliability, cost-effectiveness, collaboration,
     reproducibility, creativity, downstream impacts, and access and inclusion. These
     objectives motivate a set of best practices for cloud-native data repositories:
     analysis-ready data, cloud-optimized (ARCO) formats, and loose coupling with
     data-proximate computing. The Pangeo Project has developed a prototype
     implementation of these principles by using open-source scientific Python tools. By
     providing an ARCO data catalog together with on-demand, scalable distributed
     computing, Pangeo enables users to process big data at rates exceeding 10 GB/s.
     Several challenges must be resolved in order to realize cloud computing's full
     potential for scientific research, such as organizing funding, training users, and
     enforcing data privacy requirements.
   },
  doi={10.1109/MCSE.2021.3059437},
  ISSN={1558-366X},
  month={March},
}

@inbook{ModelNotDataWork,
   doi = {10.1145/3411764.3445518},
   author = {Sambasivan, Nithya and Kapania, Shivani and Highfill, Hannah and Akrong, Diana and Paritosh, Praveen and Aroyo, Lora M},
   title = {“{E}veryone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI},
   year = {2021},
   isbn = {9781450380966},
   publisher = {Association for Computing Machinery},
   address = {New York, NY, USA},
   url = {https://doi.org/10.1145/3411764.3445518},
   abstract = {
      AI models are increasingly applied in high-stakes domains like health and
      conservation.  Data quality carries an elevated significance in high-stakes AI due
      to its heightened downstream impact, impacting predictions like cancer detection,
      wildlife poaching, and loan allocations. Paradoxically, data is the most
      under-valued and de-glamorised aspect of AI. In this paper, we report on data
      practices in high-stakes AI, from interviews with 53 AI practitioners in India,
      East and West African countries, and USA. We define, identify, and present
      empirical evidence on Data Cascades—compounding events causing negative,
      downstream effects from data issues—triggered by conventional AI/ML practices that
      undervalue data quality. Data cascades are pervasive (92% prevalence), invisible,
      delayed, but often avoidable. We discuss HCI opportunities in designing and
      incentivizing data excellence as a first-class citizen of AI, resulting in safer
      and more robust systems for all.
   },
   booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
   articleno = {39},
   numpages = {15}
}
