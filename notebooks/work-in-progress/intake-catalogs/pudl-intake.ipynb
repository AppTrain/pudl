{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Notebook Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd Party Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from intake import open_catalog\n",
    "\n",
    "# Local Imports\n",
    "import pudl\n",
    "from pudl.output.pudltabl import PudlTabl\n",
    "from pudl.metadata.classes import Resource\n",
    "from pudl.output.epacems import year_state_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter(\"%(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up standard PUDL DB connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pudl_in': '/home/zane/code/catalyst/pudl-work',\n",
       " 'data_dir': '/home/zane/code/catalyst/pudl-work/data',\n",
       " 'settings_dir': '/home/zane/code/catalyst/pudl-work/settings',\n",
       " 'pudl_out': '/home/zane/code/catalyst/pudl-work',\n",
       " 'sqlite_dir': '/home/zane/code/catalyst/pudl-work/sqlite',\n",
       " 'parquet_dir': '/home/zane/code/catalyst/pudl-work/parquet',\n",
       " 'ferc1_db': 'sqlite:////home/zane/code/catalyst/pudl-work/sqlite/ferc1.sqlite',\n",
       " 'pudl_db': 'sqlite:////home/zane/code/catalyst/pudl-work/sqlite/pudl.sqlite',\n",
       " 'censusdp1tract_db': 'sqlite:////home/zane/code/catalyst/pudl-work/sqlite/censusdp1tract.sqlite'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "ferc1_engine = sa.create_engine(pudl_settings[\"ferc1_db\"])\n",
    "pudl_engine = sa.create_engine(pudl_settings[\"pudl_db\"])\n",
    "\n",
    "pudl_out_raw = pudl.output.pudltabl.PudlTabl(pudl_engine=pudl_engine)\n",
    "pudl_out = pudl_out_raw\n",
    "\n",
    "pudl_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential benefits of Intake catalogs:\n",
    "**Expose metadata:** The Intake catalog doesn't contain any column-level metadata, but I think it could. This would allow a user to see what columns were available, what their types were, and read their descriptions before querying the large dataset.\n",
    "\n",
    "**Local data caching:** Local file caching is not available. We would expect this to make using many small files more efficient for repeated access, since they would each only need to be transmitted over the network once. However, `fsspec` based file caching hasn't yet been implemented in the `intake-parquet` library.\n",
    "\n",
    "**Data packaging:** The catalog can be packaged and versioned using conda to manage its dependencies on other software packages and ensure compatibility. With remote access or automatic local file caching, the user also doesn't need to think about where the data is being stored, or putting it in the \"right place\" -- Intake would manage that.\n",
    "\n",
    "**Uniform API:** All the data sources of a given type (parquet, SQL) would have the same interface, reducing the number of things a user needs to remember to access the data.\n",
    "\n",
    "**Decoupling data storage location:** As with DNS, we can change / update the location where the data is being stored without impacting the user directly, since the catalog acts as a decoupling reference.\n",
    "\n",
    "## Intake References\n",
    "* [Intake Documentations](https://intake.readthedocs.io/en/latest/start.html)\n",
    "* [Intake Examples](https://github.com/intake/intake-examples)\n",
    "* [CarbonPlan Data Catalogs](https://github.com/carbonplan/data)\n",
    "* [AnacondaCon Presentation Video](https://www.youtube.com/watch?v=oyZJrROQzUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Intake & Parquet Functionality & Performance\n",
    "\n",
    "This notebook demonstrates several different ways of organizing and accessing the same EPA CEMS data:\n",
    "* Local storage on disk vs. remote storage in Google Cloud Storage buckets\n",
    "* Directly accessing the data via `pandas.read_parquet()` vs. an Intake catalog.\n",
    "* Using one big Parquet file for all data vs. separate small files for each combination of state & year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPACEMS_DIR = pudl_settings[\"parquet_dir\"] + \"/epacems\"\n",
    "\n",
    "TEST_FILTERS = year_state_filter(years=[2019, 2020], states=[\"CO\", \"TX\", \"ID\"])\n",
    "INTAKE_PATH_LOCAL = Path(os.getcwd())\n",
    "os.environ[\"INTAKE_PATH\"] = str(INTAKE_PATH_LOCAL)\n",
    "\n",
    "# Authenticated URL:\n",
    "INTAKE_PATH_REMOTE = \"gs://catalyst.coop/intake/test\"\n",
    "# Publicly visible URL:\n",
    "#INTAKE_PATH_REMOTE = \"https://storage.googleapis.com/catalyst.coop/intake/test\"\n",
    "\n",
    "local_single_file = str(INTAKE_PATH_LOCAL / \"hourly_emissions_epacems.parquet\")\n",
    "local_multi_file = str(INTAKE_PATH_LOCAL / \"hourly_emissions_epacems\")\n",
    "remote_single_file = INTAKE_PATH_REMOTE + \"/hourly_emissions_epacems.parquet\"\n",
    "remote_multi_file = INTAKE_PATH_REMOTE + \"/hourly_emissions_epacems\"\n",
    "\n",
    "pudl_catalog_path = str(INTAKE_PATH_LOCAL / \"pudl-catalog.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epacems_one_file', 'epacems_multi_file']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_cat = open_catalog(pudl_catalog_path)\n",
    "list(pudl_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'This is the catalog level description right?', 'version': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_cat.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source level description\n",
    "* Basically from the YAML file, but with some extra things, `container`, `direct_access`, `user_parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'epacems_one_file',\n",
       " 'container': 'dataframe',\n",
       " 'plugin': ['parquet'],\n",
       " 'driver': ['parquet'],\n",
       " 'description': 'Hourly EPA CEMS emissions data in a single Parquet file.',\n",
       " 'direct_access': 'forbid',\n",
       " 'user_parameters': [],\n",
       " 'metadata': {'title': 'EPA CEMS Hourly Emissions in one file',\n",
       "  'type': 'application/parquet',\n",
       "  'license': 'Creative Commons Attribution 4.0 International',\n",
       "  'license_url': 'https://creativecommons.org/licenses/by/4.0/'},\n",
       " 'args': {'engine': 'pyarrow',\n",
       "  'urlpath': '{{ env(INTAKE_PATH) }}/hourly_emissions_epacems.parquet'}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_cat.epacems_one_file.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source internals\n",
    "* Categorical values showing up as integers.\n",
    "* String values showing up as objects.\n",
    "* No length in the shape, but 19 columns.\n",
    "* `npartitions` is apparently referring to file, not row-group based partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': {'state': 'int64',\n",
       "  'plant_id_eia': 'int32',\n",
       "  'unitid': 'object',\n",
       "  'operating_datetime_utc': 'datetime64[ns, UTC]',\n",
       "  'operating_time_hours': 'float32',\n",
       "  'gross_load_mw': 'float32',\n",
       "  'steam_load_1000_lbs': 'float32',\n",
       "  'so2_mass_lbs': 'float32',\n",
       "  'so2_mass_measurement_code': 'int64',\n",
       "  'nox_rate_lbs_mmbtu': 'float32',\n",
       "  'nox_rate_measurement_code': 'int64',\n",
       "  'nox_mass_lbs': 'float32',\n",
       "  'nox_mass_measurement_code': 'int64',\n",
       "  'co2_mass_tons': 'float32',\n",
       "  'co2_mass_measurement_code': 'int64',\n",
       "  'heat_content_mmbtu': 'float32',\n",
       "  'facility_id': 'int32',\n",
       "  'unit_id_epa': 'object',\n",
       "  'year': 'int32'},\n",
       " 'shape': (None, 19),\n",
       " 'npartitions': 1,\n",
       " 'metadata': {'title': 'EPA CEMS Hourly Emissions in one file',\n",
       "  'type': 'application/parquet',\n",
       "  'license': 'Creative Commons Attribution 4.0 International',\n",
       "  'license_url': 'https://creativecommons.org/licenses/by/4.0/',\n",
       "  'catalog_dir': '/home/zane/code/catalyst/pudl/notebooks/work-in-progress/intake-catalogs/'}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_cat.epacems_one_file.discover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The other source internals\n",
    "* Here we have nullable ints, but they're 64-bit?\n",
    "* Categories show up as `category` not integers.\n",
    "* Strings show up as `string` not `object`\n",
    "* `npartitions` is referring to the separate files. How do we get information about how the partitions are structured in here?\n",
    "* Somehow in `shape` we've lost a couple of columns! There's no state or year. Probably this is because of how I converted from the old hive partitioned version of epacems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': {'plant_id_eia': 'Int64',\n",
       "  'unitid': 'string',\n",
       "  'operating_datetime_utc': 'datetime64[ns, UTC]',\n",
       "  'operating_time_hours': 'float32',\n",
       "  'gross_load_mw': 'float32',\n",
       "  'steam_load_1000_lbs': 'float32',\n",
       "  'so2_mass_lbs': 'float32',\n",
       "  'so2_mass_measurement_code': 'category',\n",
       "  'nox_rate_lbs_mmbtu': 'float32',\n",
       "  'nox_rate_measurement_code': 'category',\n",
       "  'nox_mass_lbs': 'float32',\n",
       "  'nox_mass_measurement_code': 'category',\n",
       "  'co2_mass_tons': 'float32',\n",
       "  'co2_mass_measurement_code': 'category',\n",
       "  'heat_content_mmbtu': 'float32',\n",
       "  'facility_id': 'Int64',\n",
       "  'unit_id_epa': 'string'},\n",
       " 'shape': (None, 17),\n",
       " 'npartitions': 1274,\n",
       " 'metadata': {'title': 'EPA CEMS Hourly Emissions organized by state and year.',\n",
       "  'type': 'application/parquet',\n",
       "  'license': 'Creative Commons Attribution 4.0 International',\n",
       "  'license_url': 'https://creativecommons.org/licenses/by/4.0/',\n",
       "  'catalog_dir': '/home/zane/code/catalyst/pudl/notebooks/work-in-progress/intake-catalogs/'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudl_cat.epacems_multi_file.discover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUDL Baseline\n",
    "Read the test data from your local EPA CEMS outputs directly.\n",
    "* On an SSD this should take less than 10 seconds.\n",
    "* The only `string` type columns should be `unitid` and `unit_id_epa`\n",
    "* The dataframe should take about 1.4 GB of memory and have ~8M rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pudl_epacems = pd.read_parquet(\n",
    "    EPACEMS_DIR,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=TEST_FILTERS,\n",
    "    use_nullable_dtypes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pudl_epacems.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del pudl_epacems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File Local\n",
    "For the single file local tests, download [this file](https://storage.googleapis.com/catalyst.coop/intake/test/hourly_emissions_epacems.parquet) into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct access with `read_parquet()`\n",
    "* This takes 3-4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 1.13 s, total: 5.01 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    local_single_file,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=TEST_FILTERS,\n",
    "    use_nullable_dtypes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8006424 entries, 0 to 8006423\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count    Dtype              \n",
      "---  ------                     --------------    -----              \n",
      " 0   state                      8006424 non-null  category           \n",
      " 1   plant_id_eia               8006424 non-null  Int32              \n",
      " 2   unitid                     8006424 non-null  string             \n",
      " 3   operating_datetime_utc     8006424 non-null  datetime64[ns, UTC]\n",
      " 4   operating_time_hours       8003928 non-null  float32            \n",
      " 5   gross_load_mw              8006424 non-null  float32            \n",
      " 6   steam_load_1000_lbs        33252 non-null    float32            \n",
      " 7   so2_mass_lbs               3586052 non-null  float32            \n",
      " 8   so2_mass_measurement_code  3586052 non-null  category           \n",
      " 9   nox_rate_lbs_mmbtu         3716001 non-null  float32            \n",
      " 10  nox_rate_measurement_code  3716001 non-null  category           \n",
      " 11  nox_mass_lbs               3716549 non-null  float32            \n",
      " 12  nox_mass_measurement_code  3716549 non-null  category           \n",
      " 13  co2_mass_tons              3688397 non-null  float32            \n",
      " 14  co2_mass_measurement_code  3688397 non-null  category           \n",
      " 15  heat_content_mmbtu         8006424 non-null  float32            \n",
      " 16  facility_id                8006424 non-null  Int32              \n",
      " 17  unit_id_epa                8006424 non-null  string             \n",
      " 18  year                       8006424 non-null  Int32              \n",
      "dtypes: Int32(3), category(5), datetime64[ns, UTC](1), float32(8), string(2)\n",
      "memory usage: 1.4 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Via Intake Catalog\n",
    "* This takes 3-4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 1.07 s, total: 4.09 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.environ[\"INTAKE_PATH\"] = str(INTAKE_PATH_LOCAL)\n",
    "pudl_cat = open_catalog(pudl_catalog_path)\n",
    "source = pudl_cat.epacems_one_file(filters=TEST_FILTERS)\n",
    "dd = source.to_dask()\n",
    "df = dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8006424 entries, 0 to 8006423\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count    Dtype              \n",
      "---  ------                     --------------    -----              \n",
      " 0   state                      8006424 non-null  category           \n",
      " 1   plant_id_eia               8006424 non-null  int32              \n",
      " 2   unitid                     8006424 non-null  object             \n",
      " 3   operating_datetime_utc     8006424 non-null  datetime64[ns, UTC]\n",
      " 4   operating_time_hours       8003928 non-null  float32            \n",
      " 5   gross_load_mw              8006424 non-null  float32            \n",
      " 6   steam_load_1000_lbs        33252 non-null    float32            \n",
      " 7   so2_mass_lbs               3586052 non-null  float32            \n",
      " 8   so2_mass_measurement_code  3586052 non-null  category           \n",
      " 9   nox_rate_lbs_mmbtu         3716001 non-null  float32            \n",
      " 10  nox_rate_measurement_code  3716001 non-null  category           \n",
      " 11  nox_mass_lbs               3716549 non-null  float32            \n",
      " 12  nox_mass_measurement_code  3716549 non-null  category           \n",
      " 13  co2_mass_tons              3688397 non-null  float32            \n",
      " 14  co2_mass_measurement_code  3688397 non-null  category           \n",
      " 15  heat_content_mmbtu         8006424 non-null  float32            \n",
      " 16  facility_id                8006424 non-null  int32              \n",
      " 17  unit_id_epa                8006424 non-null  object             \n",
      " 18  year                       8006424 non-null  int32              \n",
      "dtypes: category(5), datetime64[ns, UTC](1), float32(8), int32(3), object(2)\n",
      "memory usage: 1.3 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File Remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct access with `read_parquet()`\n",
    "* Using the authenticated `gs://` URL it takes **20 seconds**\n",
    "* Using the public `https://` URL this takes **10+ minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.9 s, sys: 1.17 s, total: 5.07 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    remote_single_file,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=TEST_FILTERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8006424 entries, 0 to 8006423\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count    Dtype              \n",
      "---  ------                     --------------    -----              \n",
      " 0   state                      8006424 non-null  category           \n",
      " 1   plant_id_eia               8006424 non-null  int32              \n",
      " 2   unitid                     8006424 non-null  object             \n",
      " 3   operating_datetime_utc     8006424 non-null  datetime64[ns, UTC]\n",
      " 4   operating_time_hours       8003928 non-null  float32            \n",
      " 5   gross_load_mw              8006424 non-null  float32            \n",
      " 6   steam_load_1000_lbs        33252 non-null    float32            \n",
      " 7   so2_mass_lbs               3586052 non-null  float32            \n",
      " 8   so2_mass_measurement_code  3586052 non-null  category           \n",
      " 9   nox_rate_lbs_mmbtu         3716001 non-null  float32            \n",
      " 10  nox_rate_measurement_code  3716001 non-null  category           \n",
      " 11  nox_mass_lbs               3716549 non-null  float32            \n",
      " 12  nox_mass_measurement_code  3716549 non-null  category           \n",
      " 13  co2_mass_tons              3688397 non-null  float32            \n",
      " 14  co2_mass_measurement_code  3688397 non-null  category           \n",
      " 15  heat_content_mmbtu         8006424 non-null  float32            \n",
      " 16  facility_id                8006424 non-null  int32              \n",
      " 17  unit_id_epa                8006424 non-null  object             \n",
      " 18  year                       8006424 non-null  int32              \n",
      "dtypes: category(5), datetime64[ns, UTC](1), float32(8), int32(3), object(2)\n",
      "memory usage: 1.3 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Via Intake Catalog\n",
    "* With `gs://` URL this takes **1 minute**\n",
    "* With `https://` URL it downloads a huge amount of data and then times out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "os.environ[\"INTAKE_PATH\"] = INTAKE_PATH_REMOTE\n",
    "pudl_cat = open_catalog(pudl_catalog_path)\n",
    "source = pudl_cat.epacems_one_file(filters=TEST_FILTERS)\n",
    "dd = source.to_dask()\n",
    "df = dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi File Local\n",
    "\n",
    "For the multi-file local tests download [this tarball](https://storage.googleapis.com/catalyst.coop/intake/test/hourly_emissions_epacems.tar) and extract it in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct access with `read_parquet()`\n",
    "* This takes 5 seconds, and results in an excessively large 3GB dataframe because I generated these parquet files before fixing the string-to-categorical type issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    local_multi_file,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=TEST_FILTERS,\n",
    "    use_nullable_dtypes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Via Intake Catalog\n",
    "* This takes about 15 seconds, and results in the 3GB dataframe as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "os.environ[\"INTAKE_PATH\"] = str(INTAKE_PATH_LOCAL)\n",
    "pudl_cat = open_catalog(pudl_catalog_path)\n",
    "source = pudl_cat.epacems_multi_file(\n",
    "    filters=TEST_FILTERS,\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "dd = source.to_dask()\n",
    "df = dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi File Remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct access with `read_parquet()`\n",
    "* With the `gs://` URL this takes **1 minute** and downloads minimal data.\n",
    "* With the `https://` URL this results in a 403 Forbidden error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    remote_multi_file,\n",
    "    engine=\"pyarrow\",\n",
    "    filters=TEST_FILTERS,\n",
    "    use_nullable_dtypes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Via Intake Catalog\n",
    "* With the `gs://` URL this takes **3 minutes** and downloads a little bit of data across the whole time.\n",
    "* With the `https://` URL this results in a 403 Forbidden error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "os.environ[\"INTAKE_PATH\"] = INTAKE_PATH_REMOTE\n",
    "pudl_cat = open_catalog(pudl_catalog_path)\n",
    "source = pudl_cat.epacems_multi_file(\n",
    "    filters=TEST_FILTERS,\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "dd = source.to_dask()\n",
    "df = dd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info(show_counts=True, memory_usage=\"deep\"))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Unsurprisingly, local access is blazing fast regardless of whether it's a single file or many, and while the Intake catalog access takes around 3x as long, it seems fast enough to be plenty usable.\n",
    "* Remote performance using a single file, the `gs://` protocol, and `read_parquet()` was shockingly fast. It took less than 10x as long as direct local access.\n",
    "* Remote performance over `https://` was painfully slow, to the point of being unusable in all uses of Intake. It also seemed to be transmitting far, far more data than in the `gs://` case.\n",
    "* Basically none of the `https://` cases were usable. The only one that completed took 10 minutes.\n",
    "* The only remote Intake catalog case that worked was the single-file `gs://`, which (as with the local catalogs) took about 3x as long as the `read_parquet()` case.\n",
    "* Over `https://` it seems like we can't use directories or wildcards -- we have to enumerate each filename specifically.\n",
    "* Some of the issues here have to be network speed, but I have 50-100Mbit download speeds, and the amount of data being transmitted varied widely between the different cases.\n",
    "* Still some data type issues happening in all of the Intake cases. Strings get turned into objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "* Can non-authenticated users access publicly readable data using `gs://` URLs?\n",
    "* How do we add column-level metadata to the catalog appropriately? Can we get the embedded descriptions to show up?\n",
    "* How do we add information about what's in the different partitions (i.e. split by year and state, allowable values)\n",
    "* Why are we getting jumbled nullable/non-nullable, ints/categories, strings/objects in the types?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
